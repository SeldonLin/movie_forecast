{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f184371a-804f-4c3a-9330-2b3b38c02f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from transformers import pipeline, BertModel\n",
    "from data_process import DatasetPrepare\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TextEmbedder(nn.Module):\n",
    "    def __init__(self, embedding_dim, gpu_num):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.word_embedder = pipeline('feature-extraction',model='../bert-base-uncased')\n",
    "        self.fc = nn.Linear(768, embedding_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.gpu_num = gpu_num\n",
    "\n",
    "    def forward(self, text):\n",
    "        textual_description = text\n",
    "\n",
    "        # Use BERT to extract features\n",
    "        word_embeddings = self.word_embedder(textual_description)\n",
    "\n",
    "        # BERT gives us embeddings for [CLS] ..  [EOS], which is why we only average the embeddings in the range [1:-1]\n",
    "        # We're not fine tuning BERT and we don't want the noise coming from [CLS] or [EOS]\n",
    "        word_embeddings = [torch.FloatTensor(x[0][1:-1]).mean(axis=0) for x in word_embeddings]\n",
    "        word_embeddings = torch.stack(word_embeddings)\n",
    "\n",
    "        # Embed to our embedding space\n",
    "        word_embeddings = self.dropout(self.fc(word_embeddings))\n",
    "\n",
    "        return word_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c63db51-602f-403b-b5f7-d3a8f30efa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "comment_embedding = TextEmbedder(32, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cde3dd7-c17d-4f0a-83a8-f073f84faf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_excel('dataset/data.xlsx')\n",
    "test_set = data_df.sample(n=64, random_state=21)\n",
    "train_set = data_df.drop(test_set.index)\n",
    "test_df = test_set.reset_index(drop=True)\n",
    "test_df.to_excel('dataset/test.xlsx',encoding='utf-8',index=False)\n",
    "train_df = train_set.reset_index(drop=True)\n",
    "train_df.to_excel('dataset/train.xlsx',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2006f7c-738f-4cbb-981b-4f7ce5d37990",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_excel('dataset/comment.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7621ae9d-9a8f-4ad8-8d4a-3a7578d066bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 642/642 [39:35<00:00,  3.70s/it]\n"
     ]
    }
   ],
   "source": [
    "# get comment \n",
    "comments_text_encoding = torch.zeros(len(train_df), 100, 32)\n",
    "\n",
    "# Read the descriptions and the images\n",
    "image_features, movies_description = [], []\n",
    "for (idx, row) in tqdm(train_df.iterrows(), total=len(train_df), ascii=True):\n",
    "    name = row['name']\n",
    "\n",
    "    # get comment\n",
    "    comment = comments[comments['name'] == name].head(100)\n",
    "    comment_list = list(comment['recommend'])\n",
    "    comment_text_encoding = comment_embedding(comment_list)\n",
    "    comments_text_encoding[idx] = comment_text_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c77610d2-4d50-465e-b9b4-a75f402c54e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([642, 100, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_text_encoding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "583bbce8-5c81-481e-b0cb-73a2fadf8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(comments_text_encoding,'dataset/train_comment_text_encoding.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "830416c9-094c-403b-abd1-6389f9a455fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 64/64 [03:56<00:00,  3.69s/it]\n"
     ]
    }
   ],
   "source": [
    "# get comment \n",
    "test_comment_text_encoding = torch.zeros(len(test_df), 100, 32)\n",
    "\n",
    "# Read the descriptions and the images\n",
    "for (idx, row) in tqdm(test_df.iterrows(), total=len(test_df), ascii=True):\n",
    "    name = row['name']\n",
    "\n",
    "    # get comment\n",
    "    comment = comments[comments['name'] == name].head(100)\n",
    "    comment_list = list(comment['recommend'])\n",
    "    comment_text_encoding = comment_embedding(comment_list)\n",
    "    test_comment_text_encoding[idx] = comment_text_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9b4de50-eae5-4ad7-83f6-c0aae66b5b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_comment_text_encoding,'dataset/test_comment_text_encoding.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e69373d-e08a-4964-902c-7b33a8e3fe46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comment_text_encoding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc43e1a0-2aa5-42c8-aaf4-6e2e1d9a4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comment =torch.load('dataset/test_comment_text_encoding.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc30852d-c4cf-4699-ad1a-afdbc715a958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5094, -0.0366,  0.3463,  ..., -0.0930,  0.5772,  0.1923],\n",
       "         [-0.3726,  0.2514,  0.5061,  ...,  0.2774,  0.5547,  0.4254],\n",
       "         [-0.7806, -0.1106,  0.5456,  ...,  0.5057,  0.8668,  0.3378],\n",
       "         ...,\n",
       "         [-0.7806, -0.1106,  0.5456,  ...,  0.5057,  0.8668,  0.3378],\n",
       "         [-0.7806, -0.1106,  0.5456,  ...,  0.5057,  0.8668,  0.3378],\n",
       "         [-0.7806, -0.1106,  0.5456,  ...,  0.0000,  0.0000,  0.3378]],\n",
       "\n",
       "        [[-0.3726,  0.2514,  0.5061,  ...,  0.2774,  0.5547,  0.4254],\n",
       "         [-0.0000, -0.1106,  0.5456,  ...,  0.5057,  0.8668,  0.3378],\n",
       "         [-0.3726,  0.2514,  0.5061,  ...,  0.2774,  0.5547,  0.0000],\n",
       "         ...,\n",
       "         [-0.3726,  0.0000,  0.0000,  ...,  0.2774,  0.5547,  0.0000],\n",
       "         [-0.3726,  0.2514,  0.0000,  ...,  0.2774,  0.5547,  0.4254],\n",
       "         [-0.3726,  0.2514,  0.5061,  ...,  0.2774,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0000, -0.0000,  0.5456,  ...,  0.5057,  0.8668,  0.3378],\n",
       "         [-0.5094, -0.0366,  0.3463,  ..., -0.0930,  0.5772,  0.1923],\n",
       "         [-0.3726,  0.2514,  0.5061,  ...,  0.2774,  0.5547,  0.0000],\n",
       "         ...,\n",
       "         [-0.5094, -0.0366,  0.3463,  ..., -0.0930,  0.5772,  0.1923],\n",
       "         [-0.7806, -0.1106,  0.5456,  ...,  0.5057,  0.8668,  0.3378],\n",
       "         [-0.7806, -0.0000,  0.5456,  ...,  0.0000,  0.8668,  0.3378]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.7806, -0.0000,  0.5456,  ...,  0.5057,  0.8668,  0.0000],\n",
       "         [-0.7806, -0.1106,  0.5456,  ...,  0.5057,  0.8668,  0.3378],\n",
       "         [-0.7806, -0.1106,  0.5456,  ...,  0.5057,  0.8668,  0.3378],\n",
       "         ...,\n",
       "         [-0.7806, -0.1106,  0.0000,  ...,  0.5057,  0.8668,  0.3378],\n",
       "         [-0.7806, -0.0000,  0.5456,  ...,  0.0000,  0.8668,  0.3378],\n",
       "         [-0.0000, -0.1106,  0.5456,  ...,  0.5057,  0.8668,  0.3378]],\n",
       "\n",
       "        [[-0.7806, -0.1106,  0.5456,  ...,  0.5057,  0.8668,  0.3378],\n",
       "         [-0.5094, -0.0366,  0.3463,  ..., -0.0930,  0.5772,  0.0000],\n",
       "         [-0.0000,  0.2514,  0.5061,  ...,  0.2774,  0.5547,  0.4254],\n",
       "         ...,\n",
       "         [-0.7806, -0.1106,  0.0000,  ...,  0.5057,  0.8668,  0.3378],\n",
       "         [-0.7806, -0.1106,  0.5456,  ...,  0.5057,  0.8668,  0.3378],\n",
       "         [-0.7806, -0.1106,  0.5456,  ...,  0.5057,  0.8668,  0.3378]],\n",
       "\n",
       "        [[-0.7806, -0.1106,  0.5456,  ...,  0.5057,  0.8668,  0.3378],\n",
       "         [-0.3726,  0.2514,  0.5061,  ...,  0.2774,  0.5547,  0.4254],\n",
       "         [-0.7806, -0.1106,  0.5456,  ...,  0.5057,  0.0000,  0.3378],\n",
       "         ...,\n",
       "         [ 0.0611,  0.1634,  0.1977,  ..., -0.1991,  0.7897,  0.2421],\n",
       "         [-0.5094, -0.0366,  0.3463,  ..., -0.0000,  0.0000,  0.1923],\n",
       "         [-0.5094, -0.0366,  0.3463,  ..., -0.0930,  0.5772,  0.0000]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35d91b95-e4dc-4bbb-b342-cf7e3efa3676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "introduction_embedding = TextEmbedder(32, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3409764f-4142-4a03-8a94-601c26ecca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 642/642 [00:00<00:00, 5618.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "movies_description = []\n",
    "for (idx, row) in tqdm(train_df.iterrows(), total=len(train_df), ascii=True):\n",
    "    id, name, director, actor, introduction = row['id'], row['name'], row['director'], row['actor'], row['introduction']\n",
    "\n",
    "    # get movies description\n",
    "    director = ' '.join(ast.literal_eval(director))\n",
    "    actor = ' '.join(ast.literal_eval(actor))\n",
    "    # description_tmp = director + actor + introduction\n",
    "    description_tmp = 'director:' + director +'actor:' + actor\n",
    "    movies_description.append(description_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a6b1217-4fba-49ed-bf09-8777d74e4f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "introduction_emcoding = introduction_embedding(movies_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6478701-85f7-4280-8d7d-0fc4a4ccd137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([642, 32])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introduction_emcoding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fac2928-1760-4afd-b40d-b210c770ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(introduction_emcoding,'dataset/train_introduction_emcoding.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f62e7d22-db21-4371-85e5-bf156dde373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 64/64 [00:00<00:00, 3173.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "movies_description1 = []\n",
    "for (idx, row) in tqdm(test_df.iterrows(), total=len(test_df), ascii=True):\n",
    "    id, name, director, actor, introduction = row['id'], row['name'], row['director'], row['actor'], row['introduction']\n",
    "\n",
    "    # get movies description\n",
    "    director = ' '.join(ast.literal_eval(director))\n",
    "    actor = ' '.join(ast.literal_eval(actor))\n",
    "    # description_tmp = director + actor + introduction\n",
    "    description_tmp = 'director:' + director +'actor:' + actor\n",
    "    movies_description1.append(description_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54f1ddc3-caf3-4491-9d78-68cd6395707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "introduction_emcoding1 = introduction_embedding(movies_description1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4ce4f0a-5116-408d-a800-2ad9ede6a962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introduction_emcoding1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e33aa0bc-fb48-4461-bbfd-81da8be9ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(introduction_emcoding1,'dataset/test_introduction_emcoding.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c32266c-41f8-4ad1-bd61-20242c2427b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1838,  0.2696,  0.4917,  ...,  0.3358, -0.4374,  0.4716],\n",
       "        [-0.0302,  0.3285,  0.5706,  ...,  0.3833, -0.4051,  0.5133],\n",
       "        [ 0.0000,  0.3760,  0.6099,  ...,  0.4628, -0.3481,  0.5542],\n",
       "        ...,\n",
       "        [ 0.0182,  0.4092,  0.6156,  ...,  0.4188, -0.3816,  0.4991],\n",
       "        [ 0.0331,  0.3868,  0.5983,  ...,  0.0000, -0.4241,  0.4429],\n",
       "        [-0.0000,  0.3850,  0.3614,  ...,  0.3208, -0.4255,  0.4127]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introduction_emcoding1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10aa8a2-bf86-410e-9ed9-aa3e63124c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
